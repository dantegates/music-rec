{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "try:\n",
    "    model\n",
    "except NameError:\n",
    "    model = keras.models.load_model('autoencoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.Lambda at 0x7f3410cfdc88>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('binarizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = keras.models.Model(inputs=model.input,\n",
    "                             outputs=model.get_layer('binarizer').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(1), Dimension(256)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "spec_dir = 'data/spec'\n",
    "spectrograms = [os.path.join(spec_dir, f) for f in os.listdir(spec_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn.preprocessing import maxabs_scale\n",
    "def load(f):\n",
    "    X = np.load(f).items()[0][-1]\n",
    "    return maxabs_scale(X).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  1.,  1.,  0.,\n",
       "          1.,  1.,  0.,  0.,  0.,  1.,  1.,  0.,  1.,  1.,  0.,  0.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  1.,  0.,  0.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,\n",
       "          0.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,\n",
       "          1.,  0.,  1.,  0.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.,  0.,\n",
       "          1.,  1.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  1.,\n",
       "          0.,  1.,  0.,  0.,  0.,  1.,  0.,  1.,  1.,  0.,  1.,  1.,  1.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  1.,\n",
       "          0.,  1.,  1.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,  1.,  1.,  1.,\n",
       "          1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  1.,  1.,  0.,\n",
       "          0.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          1.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,\n",
       "          0.,  0.,  1.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,\n",
       "          1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
       "          0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,\n",
       "          0.,  1.,  1.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  1.,\n",
       "          1.,  0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  0.,  0.,  1.,  0.,  0.]]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.predict(load(random.choice(spectrograms)).reshape((1, 512, 184)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "Z = np.array([2**i for i in range(64)], dtype=np.uint64).transpose()\n",
    "\n",
    "def encode_batch(encoder, files, batch_size):\n",
    "    # reading all the data at once will likely raise an Exeption.\n",
    "    # iterate through the files and yield small batches of results\n",
    "    def gen():\n",
    "        X = np.zeros((batch_size, 512, 184))\n",
    "        for i, f in enumerate(files):\n",
    "            i = i % batch_size\n",
    "            X[i,:] = load(f)\n",
    "            if i == batch_size - 1:\n",
    "                p = encoder.predict(X).astype(np.uint64)\n",
    "                # have to keep track of two keys since numpy doesn't support 64+ bit integers\n",
    "                code1 = p[:,:,:64] @ Z\n",
    "                code2 = p[:,:,64:128] @ Z\n",
    "                code3 = p[:,:,128:192] @ Z\n",
    "                code4 = p[:,:,192:256] @ Z\n",
    "                yield np.array((code1, code2, code3, code4))\n",
    "                X = np.zeros((batch_size, 512, 184))\n",
    "    return np.concatenate(list(gen()), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208952"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spectrograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "CPU times: user 35min 14s, sys: 2h 32min 6s, total: 3h 7min 21s\n",
      "Wall time: 3h 13min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "codes = encode_batch(encoder, spectrograms, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "codes = np.array(json.load(open('codes.json')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b8ac13ad34ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# why?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "codes = codes[:,:,0]  # why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 208500)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(codes.transpose(), columns=['key1', 'key2', 'key3', 'key4'])\n",
    "df['raw_path'] = spectrograms[:208500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['artist', 'album', 'track', 'seconds']] = df.raw_path.str.split('-', 3, expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key1</th>\n",
       "      <th>key2</th>\n",
       "      <th>key3</th>\n",
       "      <th>key4</th>\n",
       "      <th>raw_path</th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>track</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.017826e+18</td>\n",
       "      <td>1.395570e+19</td>\n",
       "      <td>4.700302e+18</td>\n",
       "      <td>1.144438e+19</td>\n",
       "      <td>data/spec/Deep Purple-The Very Best of Deep Pu...</td>\n",
       "      <td>data/spec/Deep Purple</td>\n",
       "      <td>The Very Best of Deep Purple Rhino</td>\n",
       "      <td>Burn.mp3</td>\n",
       "      <td>81.npz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.326642e+19</td>\n",
       "      <td>1.721681e+19</td>\n",
       "      <td>5.026499e+18</td>\n",
       "      <td>1.613927e+19</td>\n",
       "      <td>data/spec/Incubus-If Not Now When-If Not Now W...</td>\n",
       "      <td>data/spec/Incubus</td>\n",
       "      <td>If Not Now When</td>\n",
       "      <td>If Not Now When.mp3</td>\n",
       "      <td>134.npz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.347465e+19</td>\n",
       "      <td>2.457494e+18</td>\n",
       "      <td>3.653526e+18</td>\n",
       "      <td>1.218251e+19</td>\n",
       "      <td>data/spec/Pearl Jam-No Code-Around The Bend.mp...</td>\n",
       "      <td>data/spec/Pearl Jam</td>\n",
       "      <td>No Code</td>\n",
       "      <td>Around The Bend.mp3</td>\n",
       "      <td>203.npz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.893029e+18</td>\n",
       "      <td>1.062149e+19</td>\n",
       "      <td>5.115639e+18</td>\n",
       "      <td>5.540336e+18</td>\n",
       "      <td>data/spec/The Bravery-The Bravery-Aoc.mp3 - 38...</td>\n",
       "      <td>data/spec/The Bravery</td>\n",
       "      <td>The Bravery</td>\n",
       "      <td>Aoc.mp3</td>\n",
       "      <td>38.npz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.281688e+19</td>\n",
       "      <td>5.201920e+18</td>\n",
       "      <td>3.451620e+18</td>\n",
       "      <td>3.202314e+18</td>\n",
       "      <td>data/spec/Creedence Clearwater Revival-Cosmos ...</td>\n",
       "      <td>data/spec/Creedence Clearwater Revival</td>\n",
       "      <td>Cosmos Factory 2008 40th Anniversary Edition</td>\n",
       "      <td>Lookin Out My Back Door.mp3</td>\n",
       "      <td>41.npz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           key1          key2          key3          key4  \\\n",
       "0  2.017826e+18  1.395570e+19  4.700302e+18  1.144438e+19   \n",
       "1  1.326642e+19  1.721681e+19  5.026499e+18  1.613927e+19   \n",
       "2  1.347465e+19  2.457494e+18  3.653526e+18  1.218251e+19   \n",
       "3  6.893029e+18  1.062149e+19  5.115639e+18  5.540336e+18   \n",
       "4  1.281688e+19  5.201920e+18  3.451620e+18  3.202314e+18   \n",
       "\n",
       "                                            raw_path  \\\n",
       "0  data/spec/Deep Purple-The Very Best of Deep Pu...   \n",
       "1  data/spec/Incubus-If Not Now When-If Not Now W...   \n",
       "2  data/spec/Pearl Jam-No Code-Around The Bend.mp...   \n",
       "3  data/spec/The Bravery-The Bravery-Aoc.mp3 - 38...   \n",
       "4  data/spec/Creedence Clearwater Revival-Cosmos ...   \n",
       "\n",
       "                                   artist  \\\n",
       "0                   data/spec/Deep Purple   \n",
       "1                       data/spec/Incubus   \n",
       "2                     data/spec/Pearl Jam   \n",
       "3                   data/spec/The Bravery   \n",
       "4  data/spec/Creedence Clearwater Revival   \n",
       "\n",
       "                                          album                         track  \\\n",
       "0            The Very Best of Deep Purple Rhino                     Burn.mp3    \n",
       "1                               If Not Now When          If Not Now When.mp3    \n",
       "2                                       No Code          Around The Bend.mp3    \n",
       "3                                   The Bravery                      Aoc.mp3    \n",
       "4  Cosmos Factory 2008 40th Anniversary Edition  Lookin Out My Back Door.mp3    \n",
       "\n",
       "    seconds  \n",
       "0    81.npz  \n",
       "1   134.npz  \n",
       "2   203.npz  \n",
       "3    38.npz  \n",
       "4    41.npz  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('raw_path', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['artist'] = df.artist.str.split('/', expand=True)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['seconds'] = df.seconds.str.split('.', expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key1</th>\n",
       "      <th>key2</th>\n",
       "      <th>key3</th>\n",
       "      <th>key4</th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>track</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.017826e+18</td>\n",
       "      <td>1.395570e+19</td>\n",
       "      <td>4.700302e+18</td>\n",
       "      <td>1.144438e+19</td>\n",
       "      <td>Deep Purple</td>\n",
       "      <td>The Very Best of Deep Purple Rhino</td>\n",
       "      <td>Burn.mp3</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.326642e+19</td>\n",
       "      <td>1.721681e+19</td>\n",
       "      <td>5.026499e+18</td>\n",
       "      <td>1.613927e+19</td>\n",
       "      <td>Incubus</td>\n",
       "      <td>If Not Now When</td>\n",
       "      <td>If Not Now When.mp3</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.347465e+19</td>\n",
       "      <td>2.457494e+18</td>\n",
       "      <td>3.653526e+18</td>\n",
       "      <td>1.218251e+19</td>\n",
       "      <td>Pearl Jam</td>\n",
       "      <td>No Code</td>\n",
       "      <td>Around The Bend.mp3</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.893029e+18</td>\n",
       "      <td>1.062149e+19</td>\n",
       "      <td>5.115639e+18</td>\n",
       "      <td>5.540336e+18</td>\n",
       "      <td>The Bravery</td>\n",
       "      <td>The Bravery</td>\n",
       "      <td>Aoc.mp3</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.281688e+19</td>\n",
       "      <td>5.201920e+18</td>\n",
       "      <td>3.451620e+18</td>\n",
       "      <td>3.202314e+18</td>\n",
       "      <td>Creedence Clearwater Revival</td>\n",
       "      <td>Cosmos Factory 2008 40th Anniversary Edition</td>\n",
       "      <td>Lookin Out My Back Door.mp3</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           key1          key2          key3          key4  \\\n",
       "0  2.017826e+18  1.395570e+19  4.700302e+18  1.144438e+19   \n",
       "1  1.326642e+19  1.721681e+19  5.026499e+18  1.613927e+19   \n",
       "2  1.347465e+19  2.457494e+18  3.653526e+18  1.218251e+19   \n",
       "3  6.893029e+18  1.062149e+19  5.115639e+18  5.540336e+18   \n",
       "4  1.281688e+19  5.201920e+18  3.451620e+18  3.202314e+18   \n",
       "\n",
       "                         artist                                         album  \\\n",
       "0                   Deep Purple            The Very Best of Deep Purple Rhino   \n",
       "1                       Incubus                               If Not Now When   \n",
       "2                     Pearl Jam                                       No Code   \n",
       "3                   The Bravery                                   The Bravery   \n",
       "4  Creedence Clearwater Revival  Cosmos Factory 2008 40th Anniversary Edition   \n",
       "\n",
       "                          track seconds  \n",
       "0                     Burn.mp3       81  \n",
       "1          If Not Now When.mp3      134  \n",
       "2          Around The Bend.mp3      203  \n",
       "3                      Aoc.mp3       38  \n",
       "4  Lookin Out My Back Door.mp3       41  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('codes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see,\n",
    "# https://en.wikipedia.org/wiki/Hamming_distance#Algorithm_example\n",
    "def hamming(n1, n2):\n",
    "    # this number is made of each bit in either n1 or n2\n",
    "    # but not both\n",
    "    v = n1 ^ n2\n",
    "    d = 0\n",
    "    while v != 0:\n",
    "        # subtracting 1 clears the least bit, a, in v and sets all bits\n",
    "        # before a which are cleared by the logical &\n",
    "        # 2^n = sum(2^m for 0 <= m <= n-1)\n",
    "        d += 1\n",
    "        v &= v - 1\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "def query(key1, key2, key3, key4, df):\n",
    "    columns = df.columns\n",
    "    df_copy = df.copy()\n",
    "    p1 = partial(hamming, key1)\n",
    "    p2 = partial(hamming, key2)\n",
    "    p3 = partial(hamming, key3)\n",
    "    p4 = partial(hamming, key4)\n",
    "    df_copy['diffs'] = df.key1.apply(p1) \\\n",
    "                       + df.key2.apply(p2) \\\n",
    "                       + df.key3.apply(p3) \\\n",
    "                       + df.key4.apply(p4)\n",
    "    return df_copy[df_copy.diffs <= 20].sort_values('diffs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The Kinks', 'The BBC Sessions Disc II', 'Track 8.mp3 ', ' 125']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key1</th>\n",
       "      <th>key2</th>\n",
       "      <th>key3</th>\n",
       "      <th>key4</th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>track</th>\n",
       "      <th>seconds</th>\n",
       "      <th>diffs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125559</th>\n",
       "      <td>16118590657180207104</td>\n",
       "      <td>7147697225320455168</td>\n",
       "      <td>1693152819086377472</td>\n",
       "      <td>3095127896552884736</td>\n",
       "      <td>The Kinks</td>\n",
       "      <td>The BBC Sessions Disc II</td>\n",
       "      <td>Track 8.mp3</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        key1                 key2                 key3  \\\n",
       "125559  16118590657180207104  7147697225320455168  1693152819086377472   \n",
       "\n",
       "                       key4     artist                     album  \\\n",
       "125559  3095127896552884736  The Kinks  The BBC Sessions Disc II   \n",
       "\n",
       "               track seconds  diffs  \n",
       "125559  Track 8.mp3    125    0      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "key1, key2, key3, key4, *rest = next(df.sample().itertuples(index=False))\n",
    "print(rest)\n",
    "res = query(key1, key2, key3, key4, df)\n",
    "with pd.option_context('display.max_colwidth', -1):\n",
    "    display(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_batch(encoder, files, batch_size):\n",
    "    # reading all the data at once will likely raise an Exeption.\n",
    "    # iterate through the files and yield small batches of results\n",
    "    def gen():\n",
    "        X = np.zeros((batch_size, 512, 184))\n",
    "        for i, f in enumerate(files):\n",
    "            i = i % batch_size\n",
    "            X[i,:] = load(f)\n",
    "            if i == batch_size - 1:\n",
    "                print('predicting')\n",
    "                yield encoder.predict(X).reshape((batch_size, 128))\n",
    "                X = np.zeros((batch_size, 512, 184))\n",
    "    return np.concatenate(list(gen()), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n",
      "predicting\n"
     ]
    }
   ],
   "source": [
    "codes = encode_batch(encoder, spectrograms, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208500, 128)"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('raw_codes.npy', codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-473-abc9a5e05b16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/music_rec/lib/python3.5/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0mY_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m     \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_normalized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_normalized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdense_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/music_rec/lib/python3.5/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sims = cosine_similarity(codes)\n",
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = random.randint(0, len(spectrograms)-1)\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrograms[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(sims[i])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[spectrograms[j] for j in np.argsort(sims[i])[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = random.randint(0, len(spectrograms)-1)\n",
    "print(spectrograms[i])\n",
    "[spectrograms[j] for j in np.argsort(sims[i])[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = random.randint(0, len(spectrograms)-1)\n",
    "print(spectrograms[i])\n",
    "[spectrograms[j] for j in np.argsort(sims[i])[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = random.randint(0, len(spectrograms)-1)\n",
    "print(spectrograms[i])\n",
    "[spectrograms[j] for j in np.argsort(sims[i])[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = random.randint(0, len(spectrograms)-1)\n",
    "print(spectrograms[i])\n",
    "[spectrograms[j] for j in np.argsort(sims[i])[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
